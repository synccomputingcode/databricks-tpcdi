# Databricks notebook source
# MAGIC %md
# MAGIC The output folder with all the files generated by the TPC-DI `DIGen.jar` utility is first uploaded to dbfs at `FileStore/tpc-di` with a subdirectory name based on the scaling factor.
# MAGIC For instance, the files generated with a scaling factor of 10 are located at `/FileStore/tpc-di/sf10`.
# MAGIC Use this [Medium article](https://medium.com/snowflake/loading-the-tpc-di-benchmark-dataset-into-snowflake-96011e2c26cf) as a guide for generating the source files.
# MAGIC Although the overall article is about loading them to Snowflake, the portion on the `DIGen.jar` utility is applicable everywhere.
# MAGIC
# MAGIC For the XML portion, install the `com.databricks:spark-xml_2.12:0.16.0` dependency using Maven:
# MAGIC
# MAGIC ![xml-maven](files/stewart/images/xml_maven.png)
# MAGIC

# COMMAND ----------

from pyspark.sql.types import *
from pyspark.sql.functions import *

# set the scaling factor
# this controls the dbfs directory to read from
# and the schema to write to
sf = 1000
folder_path = f"/FileStore/tpc-di/sf{sf}/Batch1/"
db_schema = f"tpcdi_sf{sf}"
catalog_name = 'stewart'
delimiter = "|"

# set to use a different catalog than the default
spark.sql(f"USE CATALOG {catalog_name}").collect()
spark.sql(f"create schema if not exists {db_schema}").collect()

# create table from StructType
def create_table(
    schema: StructType, file_name: str, table_name: str, delimiter: str = delimiter
):

    df = (
        spark.read.format("csv")
        .option("inferSchema", "false")
        .option("header", "false")
        .option("sep", delimiter)
        .schema(schema)
        .load(f"{folder_path}{file_name}")
    )
    display(df)

    (
        df.write.mode("overwrite")
        .format("delta")
        .option("overwriteSchema", "true")
        .saveAsTable(f"{db_schema}.{table_name}")
    )



# COMMAND ----------

# MAGIC %md
# MAGIC Load the `DATE` table.

# COMMAND ----------

# Define the schema
schema = StructType(
    [
        StructField("SK_DATE_ID", IntegerType(), False),
        StructField("DATE_VALUE", DateType(), False),
        StructField("DATE_DESC", StringType(), False),
        StructField("CALENDAR_YEAR_ID", IntegerType(), False),
        StructField("CALENDAR_YEAR_DESC", StringType(), False),
        StructField("CALENDAR_QTR_ID", IntegerType(), False),
        StructField("CALENDAR_QTR_DESC", StringType(), False),
        StructField("CALENDAR_MONTH_ID", IntegerType(), False),
        StructField("CALENDAR_MONTH_DESC", StringType(), False),
        StructField("CALENDAR_WEEK_ID", IntegerType(), False),
        StructField("CALENDAR_WEEK_DESC", StringType(), False),
        StructField("DAY_OF_WEEK_NUM", IntegerType(), False),
        StructField("DAY_OF_WEEK_DESC", StringType(), False),
        StructField("FISCAL_YEAR_ID", IntegerType(), False),
        StructField("FISCAL_YEAR_DESC", StringType(), False),
        StructField("FISCAL_QTR_ID", IntegerType(), False),
        StructField("FISCAL_QTR_DESC", StringType(), False),
        StructField("HOLIDAY_FLAG", BooleanType(), False),
    ]
)

create_table(schema, "Date.txt", "DATE")

# COMMAND ----------

# MAGIC %md
# MAGIC Load the `DAILY_MARKET` table.

# COMMAND ----------

# Define the schema
schema = StructType(
    [
        StructField("DM_DATE", DateType(), False),
        StructField("DM_S_SYMB", StringType(), False),
        StructField("DM_CLOSE", FloatType(), False),
        StructField("DM_HIGH", FloatType(), False),
        StructField("DM_LOW", FloatType(), False),
        StructField("DM_VOL", FloatType(), False),
    ]
)

create_table(schema, "DailyMarket.txt", "DAILY_MARKET")

# COMMAND ----------

# MAGIC %md
# MAGIC Load the `INDUSTRY` table.

# COMMAND ----------

# Define the schema
schema = StructType(
    [
        StructField("IN_ID", StringType(), False),
        StructField("IN_NAME", StringType(), False),
        StructField("IN_SC_ID", StringType(), False),
    ]
)

create_table(schema, "Industry.txt", "INDUSTRY")

# COMMAND ----------

# MAGIC %md
# MAGIC Load the `PROSPECT` table.

# COMMAND ----------

# Define the schema
schema = StructType(
    [
        StructField("AGENCY_ID", StringType(), False),
        StructField("LAST_NAME", StringType(), True),
        StructField("FIRST_NAME", StringType(), True),
        StructField("MIDDLE_INITIAL", StringType(), True),
        StructField("GENDER", StringType(), True),
        StructField("ADDRESS_LINE1", StringType(), True),
        StructField("ADDRESS_LINE2", StringType(), True),
        StructField("POSTAL_CODE", StringType(), True),
        StructField("CITY", StringType(), True),
        StructField("STATE", StringType(), True),
        StructField("COUNTRY", StringType(), True),
        StructField("PHONE", StringType(), True),
        StructField("INCOME", IntegerType(), True),
        StructField("NUMBER_CARS", IntegerType(), True),
        StructField("NUMBER_CHILDREN", IntegerType(), True),
        StructField("MARITAL_STATUS", StringType(), True),
        StructField("AGE", IntegerType(), True),
        StructField("CREDIT_RATING", IntegerType(), True),
        StructField("OWN_OR_RENT_FLAG", StringType(), True),
        StructField("EMPLOYER", StringType(), True),
        StructField("NUMBER_CREDIT_CARDS", IntegerType(), True),
        StructField("NET_WORTH", IntegerType(), True),
    ]
)

create_table(schema, "Prospect.csv", "PROSPECT", ",")

# COMMAND ----------

# MAGIC %md
# MAGIC Load the `TAX_RATE` table.

# COMMAND ----------

# Define the schema
schema = StructType(
    [
        StructField("TX_ID", StringType(), False),
        StructField("TX_NAME", StringType(), True),
        StructField("TX_RATE", FloatType(), True),
    ]
)

create_table(schema, "TaxRate.txt", "TAX_RATE")

# COMMAND ----------

# MAGIC %md
# MAGIC Load the `HR` table.

# COMMAND ----------

# Define the schema
schema = StructType(
    [
        StructField("EMPLOYEE_ID", IntegerType(), False),
        StructField("MANAGER_ID", IntegerType(), False),
        StructField("EMPLOYEE_FIRST_NAME", StringType(), True),
        StructField("EMPLOYEE_LAST_NAME", StringType(), True),
        StructField("EMPLOYEE_MI", StringType(), True),
        StructField("EMPLOYEE_JOB_CODE", IntegerType(), True),
        StructField("EMPLOYEE_BRANCH", StringType(), True),
        StructField("EMPLOYEE_OFFICE", StringType(), True),
        StructField("EMPLOYEE_PHONE", StringType(), True)
    ]
)

create_table(schema, "HR.csv", "HR", ",")

# COMMAND ----------

# MAGIC %md
# MAGIC Load the `WATCH_HISTORY` table.

# COMMAND ----------

# Define the schema
schema = StructType(
    [
        StructField("W_C_ID", IntegerType(), False),
        StructField("W_S_SYMB", StringType(), True),
        StructField("W_DTS", TimestampType(), True),
        StructField("W_ACTION", StringType(), True),
    ]
)

create_table(schema, "WatchHistory.txt", "WATCH_HISTORY")

# COMMAND ----------

# MAGIC %md
# MAGIC Load the `TRADE` table.

# COMMAND ----------

# Define the schema
schema = StructType(
    [
        StructField("T_ID", IntegerType(), False),
        StructField("T_DTS", TimestampType(), False),
        StructField("T_ST_ID", StringType(), False),
        StructField("T_TT_ID", StringType(), False),
        StructField("T_IS_CASH", BooleanType(), False),
        StructField("T_S_SYMB", StringType(), False),
        StructField("T_QTY", FloatType(), False),
        StructField("T_BID_PRICE", FloatType(), False),
        StructField("T_CA_ID", IntegerType(), False),
        StructField("T_EXEC_NAME", StringType(), False),
        StructField("T_TRADE_PRICE", FloatType(), True),
        StructField("T_CHRG", FloatType(), True),
        StructField("T_COMM", FloatType(), True),
        StructField("T_TAX", FloatType(), True),
    ]
)

create_table(schema, "Trade.txt", "TRADE")

# COMMAND ----------

# MAGIC %md
# MAGIC Load the `TRADE_HISTORY` table.

# COMMAND ----------

# Define the schema
schema = StructType(
    [
        StructField("TH_T_ID", IntegerType(), False),
        StructField("TH_DTS", TimestampType(), False),
        StructField("TH_ST_ID", StringType(), False),
    ]
)

create_table(schema, "TradeHistory.txt", "TRADE_HISTORY")

# COMMAND ----------

# MAGIC %md
# MAGIC Load the `STATUS_TYPE` table.

# COMMAND ----------

# Define the schema
schema = StructType(
    [
        StructField("ST_ID", StringType(), False),
        StructField("ST_NAME", StringType(), False),
    ]
)

create_table(schema, "StatusType.txt", "STATUS_TYPE")

# COMMAND ----------

# MAGIC %md
# MAGIC Load the `TRADE_TYPE` table.

# COMMAND ----------

# Define the schema
schema = StructType(
    [
        StructField("TT_ID", StringType(), False),
        StructField("TT_NAME", StringType(), False),
        StructField("TT_IS_SELL", BooleanType(), False),
        StructField("TT_IS_MARKET", BooleanType(), False),
    ]
)

create_table(schema, "TradeType.txt", "TRADE_TYPE")

# COMMAND ----------

# MAGIC %md
# MAGIC Load the `HOLDING_HISTORY` table.

# COMMAND ----------

# Define the schema
schema = StructType(
    [
        StructField("HH_H_T_ID", IntegerType(), False),
        StructField("HH_T_ID", IntegerType(), False),
        StructField("HH_BEFORE_QTY", FloatType(), False),
        StructField("HH_AFTER_QTY", FloatType(), False),
    ]
)

create_table(schema, "HoldingHistory.txt", "HOLDING_HISTORY")

# COMMAND ----------

# MAGIC %md
# MAGIC Load the `CASH_TRANSATION` table.

# COMMAND ----------

# Define the schema
schema = StructType(
    [
        StructField("CT_CA_ID", IntegerType(), False),
        StructField("CT_DTS", TimestampType(), False),
        StructField("CT_AMT", FloatType(), False),
        StructField("CT_NAME", StringType(), False),
    ]
)

create_table(schema, "CashTransaction.txt", "CASH_TRANSACTION")

# COMMAND ----------

# MAGIC %md
# MAGIC Using the FINWIRE (financial wire) files, create a temporary view that has the 2 shared columns, including the one we need to filter on.

# COMMAND ----------

# These are fixed-width fields, so read the entire line in as "line"
schema = StructType(
    [
        StructField("line", StringType(), False),
    ]
)

# generic dataframe for all record types
# create a temporary view
df = (
    spark.read.format("csv")
    .option("inferSchema", "false")
    .option("header", "false")
    .option("sep", delimiter)
    .schema(schema)
    .load(f"{folder_path}FINWIRE??????")
    .withColumn("rec_type", substring("line", 16, 3))
    .withColumn("pts", to_timestamp(substring("line", 0, 15), "yyyyMMdd-HHmmss"))
    .createOrReplaceTempView("finwire")
)


# COMMAND ----------

# MAGIC %md
# MAGIC Create the `CMP` table, which contains Company records

# COMMAND ----------

df = (
    spark.table("finwire")
    .where(col("rec_type") == "CMP")
    .withColumn("company_name", substring("line", 19, 60))
    .withColumn("cik", substring("line", 79, 10))
    .withColumn("status", substring("line", 89, 4))
    .withColumn("industry_id", substring("line", 93, 2))
    .withColumn("sp_rating", substring("line", 95, 4))
    .withColumn(
        "founding_date",
        to_date(
            substring("line", 99, 8),
            'yyyymmdd'
        )
    )
    .withColumn("address_line1", substring("line", 107, 80))
    .withColumn("address_line2", substring("line", 187, 80))
    .withColumn("postal_code", substring("line", 267, 12))
    .withColumn("city", substring("line", 279, 25))
    .withColumn("state_province", substring("line", 304, 20))
    .withColumn("country", substring("line", 324, 24))
    .withColumn("ceo_name", substring("line", 348, 46))
    .withColumn("description", substring("line", 394, 150))
    .drop("line", "rec_type")
)
display(df)

(
    df.write.mode("overwrite")
    .format("delta")
    .option("overwriteSchema", "true")
    .saveAsTable(f"{db_schema}.cmp")
)

# COMMAND ----------

# MAGIC %md
# MAGIC Create the `SEC` table, which contains Security records

# COMMAND ----------

df = (
    spark.table("finwire")
    .where(col("rec_type") == "SEC")
    .withColumn("symbol", substring("line", 19, 15))
    .withColumn("issue_type", substring("line", 34, 6))
    .withColumn("status", substring("line", 40, 4))
    .withColumn("name", substring("line", 44, 70))
    .withColumn("ex_id", substring("line", 114, 6))
    .withColumn("sh_out", substring("line", 120, 13))
    .withColumn("first_trade_date", substring("line", 133, 8))
    .withColumn("first_exchange_date", substring("line", 141, 8))
    .withColumn("dividend", substring("line", 149, 12))
    .withColumn("co_name_or_cik", substring("line", 161, 60))
    .drop("line", "rec_type")
)
display(df)

(
    df.write.mode("overwrite")
    .format("delta")
    .option("overwriteSchema", "true")
    .saveAsTable(f"{db_schema}.sec")
)

# COMMAND ----------

# MAGIC %md
# MAGIC Create the `FIN` table, which contains Financial records

# COMMAND ----------

df = (
    spark.table("finwire")
    .where(col("rec_type") == "FIN")
    .withColumn("year", substring("line", 19, 4))
    .withColumn("quarter", substring("line", 23, 1))
    .withColumn("quarter_start_date", substring("line", 24, 8))
    .withColumn("posting_date", substring("line", 32, 8))
    .withColumn("revenue", substring("line", 40, 17))
    .withColumn("earnings", substring("line", 57, 17))
    .withColumn("eps", substring("line", 74, 12))
    .withColumn("diluted_eps", substring("line", 86, 12))
    .withColumn("margin", substring("line", 98, 12))
    .withColumn("inventory", substring("line", 110, 17))
    .withColumn("assets", substring("line", 127, 17))
    .withColumn("liabilities", substring("line", 144, 17))
    .withColumn("sh_out", substring("line", 161, 13))
    .withColumn("diluted_sh_out", substring("line", 174, 13))
    .withColumn("co_name_or_cik", substring("line", 187, 60))
    .drop("line", "rec_type")
)
display(df)

(
    df.write.mode("overwrite")
    .format("delta")
    .option("overwriteSchema", "true")
    .saveAsTable(f"{db_schema}.fin")
)

# COMMAND ----------

# MAGIC %md
# MAGIC Load the `CUSTOMER_MGMT` table. Ensure the `com.databricks.spark.xml` library is loaded.

# COMMAND ----------

# Simplifies the logic for constructing a phone number from multiple nested fields
# Only used it three times, but it's worth it
def get_phone_number(
        phone_id:str,
        separator:str = '-'
):
    return concat(
        coalesce(col(f"contact_info.C_PHONE_{phone_id}.C_CTRY_CODE"), lit('')),
        when(col(f"contact_info.C_PHONE_{phone_id}.C_CTRY_CODE").isNull(), '').otherwise(separator),
        coalesce(col(f"contact_info.C_PHONE_{phone_id}.C_AREA_CODE"), lit('')),
        when(col(f"contact_info.C_PHONE_{phone_id}.C_AREA_CODE").isNull(), '').otherwise(separator),
        coalesce(col(f"contact_info.C_PHONE_{phone_id}.C_LOCAL"), lit('')),
        when(col(f"contact_info.C_PHONE_{phone_id}.C_EXT").isNull(), '').otherwise(" ext: "),
        coalesce(col(f"contact_info.C_PHONE_{phone_id}.C_EXT"), lit(''))
).alias(f"c_phone_{phone_id}")

df = (
    spark.read.format("com.databricks.spark.xml")
    .option("inferSchema", "true")
    .option("rowTag","TPCDI:Action")
    .option('nullValue', "")
    .load(f"{folder_path}CustomerMgmt.xml")
    .withColumn('account', col('Customer.Account'))
    .withColumn('address', col('Customer.Address'))
    .withColumn('contact_info', col('Customer.ContactInfo'))
    .withColumn('name', col('Customer.Name'))
    .withColumn('tax_info', col('Customer.TaxInfo'))
    .select(
        col('_ActionTS').alias('action_ts'),
        col('_ActionType').alias('action_type'),
        col('Customer._C_ID').alias('c_id'),
        col('Customer._C_TAX_ID').alias('c_tax_id'),
        col('Customer._C_GNDR').alias('c_gndr'),
        col('Customer._C_TIER').alias('c_tier'),
        col('Customer._C_DOB').alias('c_dob'),
        col('name.C_L_NAME').alias('c_l_name'),
        col('name.C_F_NAME').alias('c_f_name'),
        col('name.C_M_NAME').alias('c_m_name'),
        col('address.C_ADLINE1').alias('c_adline1'),
        col('address.C_ADLINE2').alias('c_adline2'),
        col('address.C_CITY').alias('c_city'),
        col('address.C_CTRY').alias('c_ctry'),
        col('address.C_STATE_PROV').alias('c_state_prov'),
        col('address.C_ZIPCODE').alias('c_zipcode'),
        col('contact_info.C_PRIM_EMAIL').alias('c_prim_email'),
        col('contact_info.C_ALT_EMAIL').alias('c_alt_email'),
        get_phone_number(1),
        get_phone_number(2),
        get_phone_number(3),
        col('tax_info.C_LCL_TX_ID').alias('c_lcl_tx_id'),
        col('tax_info.C_NAT_TX_ID').alias('c_nat_tx_id'),
        col('account._CA_ID').alias('ca_id'),
        col('account._CA_TAX_ST').alias('ca_tax_st'),
        col('account.CA_B_ID').alias('ca_b_id'),
        col('account.CA_NAME').alias('ca_name'),
    )
)

display(df)

(
    df.write.mode("overwrite")
    .format("delta")
    .option("overwriteSchema", "true")
    .saveAsTable(f"{db_schema}.customer_mgmt")
)
